{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "# Combine the dataframes\n",
    "for filename in listdir(\"dataset\\\\dataset\\\\train\\\\boxes_transcripts_labels\\\\\"):\n",
    "    df_temp = pd.read_csv(\"dataset\\\\dataset\\\\train\\\\boxes_transcripts_labels\\\\\" + filename, sep = \",\", header = None)\n",
    "    df_temp.columns = ['start_index', 'end_index', 'x_top_left', 'y_top_left', 'x_bottom_right', 'y_bottom_right','transcript','field']\n",
    "    #df_temp_trimmed = df_temp.loc[df_temp['field'] != 'OTHER']\n",
    "\n",
    "    df = pd.concat([df, df_temp], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we build the model and the preprocessing functions based on our analysis\n",
    "def Feature_Engineering(df, type = 'train'):\n",
    "    df['x_center'] = df[['x_top_left', 'x_bottom_right']].mean(axis=1)\n",
    "    df['y_center'] = df[['y_top_left', 'y_bottom_right']].mean(axis=1)\n",
    "    df['index_len'] = df['end_index'] - df['start_index']\n",
    "\n",
    "    # We select 5 features told to us by RFECV and the label\n",
    "    df = df[['start_index', 'end_index', 'x_center', 'y_center', 'index_len', 'field']]\n",
    "\n",
    "    return df\n",
    "\n",
    "def X_y_split(df):\n",
    "    y = df[['field']]\n",
    "    X = df[['start_index', 'end_index', 'x_center', 'y_center', 'index_len']]\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hierarchical_Training(df, model1, model2, type = \"Not Complete\"):\n",
    "    df1 = Feature_Engineering(df)\n",
    "    df2 = df1.copy()\n",
    "\n",
    "    # For 1st model, we convert relevant columns as \"not other\"  & We reduce the number of \"OTHER\" columns to reduce skewness\n",
    "    df1.loc[df[\"field\"] != \"OTHER\", \"field\"] = 'NOT_OTHER'\n",
    "\n",
    "    # For 2nd model, we simply drop all rows with 'OTHER' as label\n",
    "    df2 = df2.loc[df2['field'] != 'OTHER']\n",
    "\n",
    "    if type == \"Final\":\n",
    "        model1 = Train_Model(df1, model1, type)\n",
    "        model2 = Train_Model(df2, model2, type)\n",
    "        return model1, model2\n",
    "    \n",
    "    else:\n",
    "        model1, y_pred_1, y_test_1 = Train_Model(df1, model1)\n",
    "        model2, y_pred_2, y_test_2 = Train_Model(df2, model2)\n",
    "\n",
    "        return model1, model2, y_pred_1, y_pred_2, y_test_1, y_test_2\n",
    "\n",
    "\n",
    "def Train_Model(df, model, type = \"Not Complete\"):\n",
    "    X,y = X_y_split(df)\n",
    "    \n",
    "    if type == \"Final\":\n",
    "        model.fit(X,y)\n",
    "        return model\n",
    "    \n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        return model, y_pred, y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Cross_Validation(df, model):\n",
    "    \n",
    "    X,y = X_y_split(df)\n",
    "\n",
    "    # Create StratifiedKFold object.\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    accu_stratified = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train_fold, X_test_fold = X.values[train_index], X.values[test_index]\n",
    "        y_train_fold, y_test_fold = y.values[train_index], y.values[test_index]\n",
    "        model.fit(X_train_fold, y_train_fold.ravel())\n",
    "        accu_stratified.append(model.score(X_test_fold, y_test_fold))\n",
    "    \n",
    "    return(accu_stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration value:  1\n",
      "\n",
      "Average Accuracy That can be obtained from this model is: 97.5426726992226 %\n",
      "iteration value:  2\n",
      "\n",
      "Average Accuracy That can be obtained from this model is: 97.20431209936227 %\n",
      "iteration value:  4\n",
      "\n",
      "Average Accuracy That can be obtained from this model is: 98.29346482013014 %\n",
      "iteration value:  8\n",
      "\n",
      "Average Accuracy That can be obtained from this model is: 98.62382986741606 %\n",
      "iteration value:  16\n",
      "\n",
      "Average Accuracy That can be obtained from this model is: 98.71389090191464 %\n",
      "iteration value:  32\n",
      "\n",
      "Average Accuracy That can be obtained from this model is: 98.74755905805958 %\n",
      "iteration value:  64\n",
      "\n",
      "Average Accuracy That can be obtained from this model is: 98.76397197733067 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Application Assignments\\Infrrd-Assignment\\main 2.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Application%20Assignments/Infrrd-Assignment/main%202.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df2 \u001b[39m=\u001b[39m df2\u001b[39m.\u001b[39mloc[df2[\u001b[39m'\u001b[39m\u001b[39mfield\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mOTHER\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Application%20Assignments/Infrrd-Assignment/main%202.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators \u001b[39m=\u001b[39m i)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Application%20Assignments/Infrrd-Assignment/main%202.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m cv_score \u001b[39m=\u001b[39m Cross_Validation(df1, model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Application%20Assignments/Infrrd-Assignment/main%202.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Print the output.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Application%20Assignments/Infrrd-Assignment/main%202.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39miteration value: \u001b[39m\u001b[39m'\u001b[39m, i)\n",
      "\u001b[1;32md:\\Application Assignments\\Infrrd-Assignment\\main 2.ipynb Cell 5\u001b[0m line \u001b[0;36mCross_Validation\u001b[1;34m(df, model)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Application%20Assignments/Infrrd-Assignment/main%202.ipynb#W4sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     X_train_fold, X_test_fold \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mvalues[train_index], X\u001b[39m.\u001b[39mvalues[test_index]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Application%20Assignments/Infrrd-Assignment/main%202.ipynb#W4sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     y_train_fold, y_test_fold \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mvalues[train_index], y\u001b[39m.\u001b[39mvalues[test_index]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Application%20Assignments/Infrrd-Assignment/main%202.ipynb#W4sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train_fold, y_train_fold\u001b[39m.\u001b[39;49mravel())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Application%20Assignments/Infrrd-Assignment/main%202.ipynb#W4sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     accu_stratified\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mscore(X_test_fold, y_test_fold))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Application%20Assignments/Infrrd-Assignment/main%202.ipynb#W4sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mreturn\u001b[39;00m(accu_stratified)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\sklearn\\tree\\_classes.py:284\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m is_classification:\n\u001b[1;32m--> 284\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    285\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[0;32m    287\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\sklearn\\utils\\multiclass.py:207\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_classification_targets\u001b[39m(y):\n\u001b[0;32m    196\u001b[0m     \u001b[39m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \n\u001b[0;32m    198\u001b[0m \u001b[39m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39m        Target values.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m     y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    208\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    210\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m     ]:\n\u001b[0;32m    215\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    216\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m{\u001b[39;00my_type\u001b[39m}\u001b[39;00m\u001b[39m. Maybe you are trying to fit a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mclassifier, which expects discrete classes on a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mregression target with continuous values.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\sklearn\\utils\\multiclass.py:381\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39misdtype(y\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mreal floating\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    379\u001b[0m     \u001b[39m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[39;00m\n\u001b[0;32m    380\u001b[0m     data \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m issparse(y) \u001b[39melse\u001b[39;00m y\n\u001b[1;32m--> 381\u001b[0m     \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39many(data \u001b[39m!=\u001b[39m xp\u001b[39m.\u001b[39;49mastype(data, \u001b[39mint\u001b[39;49m)):\n\u001b[0;32m    382\u001b[0m         _assert_all_finite(data, input_name\u001b[39m=\u001b[39minput_name)\n\u001b[0;32m    383\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.virtualenvs\\researchvenv\\lib\\site-packages\\sklearn\\utils\\_array_api.py:245\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.astype\u001b[1;34m(self, x, dtype, copy, casting)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m, x, dtype, \u001b[39m*\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    244\u001b[0m     \u001b[39m# astype is not defined in the top level NumPy namespace\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mastype(dtype, copy\u001b[39m=\u001b[39;49mcopy, casting\u001b[39m=\u001b[39;49mcasting)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This will help us choose the hyperparameters for our models using Cross Validation\n",
    "new_df = df.copy()\n",
    "for i in [1,2,4,8,16,32,64,100,200,300]:\n",
    "        df1 = Feature_Engineering(new_df)\n",
    "        df2 = df1.copy()\n",
    "\n",
    "        # For 1st model, we convert relevant columns as \"not other\"\n",
    "        df1.loc[df[\"field\"] != \"OTHER\", \"field\"] = 'NOT_OTHER'\n",
    "\n",
    "        # For 2nd model, we simply drop all rows with 'OTHER' as label\n",
    "        df2 = df2.loc[df2['field'] != 'OTHER']\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators = i)\n",
    "        cv_score = Cross_Validation(df1, model)\n",
    "\n",
    "        # Print the output.\n",
    "        print('iteration value: ', i)\n",
    "        print('\\nAverage Accuracy That can be obtained from this model is:',\n",
    "        np.mean(cv_score)*100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researchvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
